{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rRd71b6bEMc"
      },
      "source": [
        "# Sheet 3 - Sergio Amortegui, Juan David Forero, Navid Esteban Mejia"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWlyFXVWbEMe"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wbWg6DEJkdig"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import numbers\n",
        "import itertools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPVdM8tDkdih"
      },
      "source": [
        "## Exercise 2\n",
        "Use the credits.csv for all the tasks in this exercise (iris datasets\n",
        "only for some unit tests). You might stumble over some difficulties and may want to check\n",
        "the replace and fillna function of Pandas data frames to get rid of missing values. Do not\n",
        "use the get_dummies, digitize, cut, crosstab (or any similar) function in this exercise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1md1ctlkdii"
      },
      "source": [
        "### 1 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gY-Iux5kdii"
      },
      "source": [
        "#### a)\n",
        "Write a function binarizeCategoricalAttributeVector(column) that takes a\n",
        "categorical attribute vector (do not assume a categorical Pandas type) and re-\n",
        "turns an n ×m dimensional numpy array, where m is the number of categorical\n",
        "values occurring in the column and n is the length of the original column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ksrDfHLtkdij"
      },
      "outputs": [],
      "source": [
        "def binarizeCategoricalAttributeVector(column):\n",
        "    n = len(column)\n",
        "    m = set(column)\n",
        "    itemIndex = {}\n",
        "    count = 0\n",
        "\n",
        "    for item in m:\n",
        "      itemIndex[item] = count\n",
        "      count += 1\n",
        "\n",
        "    arr = np.zeros((n,len(m)), dtype=int)\n",
        "    for index, item in enumerate(column):\n",
        "      arr[index][itemIndex[item]] = 1\n",
        "\n",
        "    return arr\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRihha3tkdij"
      },
      "source": [
        "#### b)\n",
        "Then write a function getCategoricalAttributes(df) that returns a list of column names of a Pandas DataFrame that contain non-numeric values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "fmaMdJjyuqjf"
      },
      "outputs": [],
      "source": [
        "def getCategoricalAttributes(df):\n",
        "  return(df.select_dtypes(exclude=['int64','float64']).columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hF7f39Izkdik"
      },
      "source": [
        "#### c)\n",
        "Finally, write a function readFrameAsMatrix(df) to convert a given DataFrame\n",
        "into a purely numeric nd array such that each categorical attribute with m values\n",
        "is converted into m binary attributes (columns)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "N-i3osP5kdik"
      },
      "outputs": [],
      "source": [
        "def readFrameAsMatrix(df):\n",
        "  # use getCategoricalAttributes and binarize to complete de point\n",
        "  return df.to_numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_dTdkrZkdik"
      },
      "source": [
        "#### Tests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ZiVLz_Cnkdil"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------\n",
            "Binarization check\n",
            "-----------------\n",
            "Dimension check: OK\n",
            "Occurring values: OK\n",
            "Coherence: OK\n",
            "-----------------\n",
            "Check of category detection\n",
            "-----------------\n",
            "Categorical attribute detection: OK\n",
            "-----------------\n",
            "Conversion check for data frames\n",
            "-----------------\n",
            "Outer Type check: OK\n",
            "Inner Type check: FAIL (dtype of matrix should be something numeric like float and not object)\n",
            "Dimensionality check: FAIL (expected shape 48842 x 110, but observed shape 48842 x 15)\n"
          ]
        }
      ],
      "source": [
        "def check_column_conversion(column):\n",
        "    M = binarizeCategoricalAttributeVector(column)\n",
        "    vals = list(np.unique(M))\n",
        "    sorted(vals)\n",
        "    print(\"-----------------\\nBinarization check\\n-----------------\")\n",
        "    print(\"Dimension check: \" + (\"OK\" if M.shape == (len(column), len(np.unique(column))) else \"FAIL\"))\n",
        "    print(\"Occurring values: \" + (\"OK\" if vals == [0, 1] else \"FAIL (there should only be 0s and 1s in the output.)\"))\n",
        "    print(\"Coherence: \" + (\"OK\" if all(np.sum(M, axis=1) == np.ones(len(column))) else \"FAIL (all rows must sum up to 1)\"))\n",
        "\n",
        "def check_category_detection(df, expectedcols):\n",
        "    print(\"-----------------\\nCheck of category detection\\n-----------------\")\n",
        "    act = getCategoricalAttributes(df)\n",
        "    missing = [c for c in expectedcols if not c in act]\n",
        "    unexpected = [c for c in act if not c in expectedcols]\n",
        "    print(\"Categorical attribute detection: \" + (\"OK\" if len(missing) + len(unexpected) == 0 else \"FAIL (undetected columns: \" + str(missing) + \", wrongly detected columns: \" + str(unexpected) + \")\"))\n",
        "    \n",
        "def check_frame_conversion(df, num_expected_columns):\n",
        "    print(\"-----------------\\nConversion check for data frames\\n-----------------\")\n",
        "    A = readFrameAsMatrix(df)\n",
        "    print(\"Outer Type check: \" + (\"OK\" if type(A) == np.ndarray else \"FAIL (not a numpy array but \" + str(type(A)) + \")\"))\n",
        "    print(\"Inner Type check: \" + (\"OK\" if A.dtype in [float, np.float32, np.float64] else \"FAIL (dtype of matrix should be something numeric like float and not \" + str(A.dtype) + \")\"))\n",
        "    print(\"Dimensionality check: \" + (\"OK\" if len(A) == len(df) and A.shape[1] == num_expected_columns else \"FAIL (expected shape \" + str(len(df)) + \" x \" + str(num_expected_columns) + \", but observed shape \" + str(len(A)) + \" x \" + str(A.shape[1]) + \")\"))\n",
        "\n",
        "\n",
        "## unit test for conversion functions\n",
        "dfCreditTest = pd.read_csv(\"credits.csv\")\n",
        "check_column_conversion(dfCreditTest.values[:,1])\n",
        "check_category_detection(dfCreditTest, ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country', 'class'])\n",
        "check_frame_conversion(dfCreditTest, 110)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxVmQJ85kdil"
      },
      "source": [
        "### 2\n",
        "This exercise is about discretizing attributes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### a)\n",
        "Write a function discretizeBasedOnThresholds(column, thresholds, names=None)\n",
        "that takes a vector of observations, the desired thresholds and optionally names for\n",
        "the bins; if no names are given, name the bins c0,c1,... The first bin contains all\n",
        "instances with values at most the lowest threshold, and the last bin contains all\n",
        "instances with values greater than the biggest threshold. Hence, the number of\n",
        "bins is the number of thresholds + 1. The function should return a vector with the\n",
        "discretized values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [],
      "source": [
        "def discretizeBasedOnThresholds(column, thresholds, names=None):\n",
        "    if names == None:\n",
        "        names = [f'c{i}' for i in range(len(thresholds)+1)]\n",
        "    \n",
        "    result = []\n",
        "\n",
        "    min_val = thresholds[0]\n",
        "    max_val = thresholds[-1]\n",
        "    for item in column:\n",
        "        if item <= min_val:\n",
        "            result.append(names[0])\n",
        "            continue\n",
        "        if item > max_val:\n",
        "            result.append(names[-1])\n",
        "            continue \n",
        "        for index, current in enumerate(thresholds):\n",
        "            if(index < len(thresholds) - 1):\n",
        "                if item > current and item <= thresholds[index+1]:\n",
        "                    result.append(names[index+1])\n",
        "                    break\n",
        "\n",
        "    return result \n",
        "\n",
        "\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### b)\n",
        "Write functions discretizeEqualLength(column, k, names = None) and\n",
        "discretizeEqualFrequency(column, k, names = None) that convert a numeric\n",
        "attribute vector into a discrete attribute vector, applying the respective technique\n",
        "for a specified number of bins or frequency. The parameter k is for the number of\n",
        "bins. Use the above function to realize these two.\n",
        "Hint: Only compute thresholds and then use the first function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {},
      "outputs": [],
      "source": [
        "def discretizeEqualLength(column, k, names = None):\n",
        "    range_column = max(column) - min(column)\n",
        "    length  = (range_column / k) \n",
        "    thresholds = [min(column) + length * i for i in range(1, k)]\n",
        "\n",
        "    result = discretizeBasedOnThresholds(column, thresholds, names)\n",
        "    return result "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def discretizeEqualFrequency(column, k, names = None):\n",
        "    lib = {key: 0 for key in column}\n",
        "    for item in column:\n",
        "        lib[item] += 1\n",
        "\n",
        "    data_length = len(column) / (k)\n",
        "    threshold = [data_length * i for i in range(1,k)]\n",
        "\n",
        "    current = 0 \n",
        "    for value,frequency in lib.items():\n",
        "        if current + frequency <= data_length:\n",
        "            current += frequency\n",
        "        else:\n",
        "            current = 0\n",
        "            threshold.append(value)\n",
        "    \n",
        "    return discretizeBasedOnThresholds(column, threshold, names)\n",
        "    print(threshold)\n",
        "    \n",
        "    print(lib)\n",
        "    print(len(column))\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {
        "id": "7J80CD4wkdil"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Conversion test: OK\n",
            "Conversion test: OK\n",
            "Equal Length Discretization: OK\n",
            "Equal Count Discretization: FAIL\n",
            "['c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0', 'c0']\n",
            "['c0' 'c0' 'c0' 'c0' 'c0' 'c1' 'c0' 'c0' 'c0' 'c0' 'c1' 'c0' 'c0' 'c0'\n",
            " 'c1' 'c1' 'c1' 'c0' 'c1' 'c0' 'c1' 'c0' 'c0' 'c0' 'c0' 'c0' 'c0' 'c1'\n",
            " 'c1' 'c0' 'c0' 'c1' 'c1' 'c1' 'c0' 'c0' 'c1' 'c0' 'c0' 'c0' 'c0' 'c0'\n",
            " 'c0' 'c0' 'c0' 'c0' 'c0' 'c0' 'c1' 'c0' 'c3' 'c2' 'c3' 'c1' 'c3' 'c1'\n",
            " 'c2' 'c0' 'c3' 'c1' 'c0' 'c2' 'c2' 'c2' 'c1' 'c3' 'c1' 'c1' 'c2' 'c1'\n",
            " 'c2' 'c2' 'c2' 'c2' 'c2' 'c3' 'c3' 'c3' 'c2' 'c1' 'c1' 'c1' 'c1' 'c2'\n",
            " 'c1' 'c2' 'c3' 'c2' 'c1' 'c1' 'c1' 'c2' 'c1' 'c0' 'c1' 'c1' 'c1' 'c2'\n",
            " 'c0' 'c1' 'c2' 'c1' 'c3' 'c2' 'c3' 'c3' 'c0' 'c3' 'c3' 'c3' 'c3' 'c2'\n",
            " 'c3' 'c1' 'c1' 'c2' 'c3' 'c3' 'c3' 'c2' 'c3' 'c1' 'c3' 'c2' 'c3' 'c3'\n",
            " 'c2' 'c2' 'c2' 'c3' 'c3' 'c3' 'c2' 'c2' 'c2' 'c3' 'c2' 'c2' 'c2' 'c3'\n",
            " 'c3' 'c3' 'c1' 'c3' 'c3' 'c3' 'c2' 'c3' 'c2' 'c2']\n"
          ]
        }
      ],
      "source": [
        "def test_discretization(column, thresholds, names, expected):\n",
        "    conv = discretizeBasedOnThresholds(column, thresholds, names)\n",
        "    print(\"Conversion test: \" + (\"OK\" if len(conv) == len(expected) and conv == expected else \"FAIL (expected \\\"\" + str(expected) +\"\\\" but observed \\\"\" + str(conv) + \"\\\")\"))\n",
        "def test_equal_length_discretization(arr, k, expected):\n",
        "    act = discretizeEqualLength(arr, k)\n",
        "    print (\"Equal Length Discretization: \" + (\"OK\" if all(act == expected) else \"FAIL\"))\n",
        "    # print([(index, act[index] == expected[index], act[index], expected[index]) for index in range(len(act))])\n",
        "    \n",
        "def test_equal_count_discretization(arr, k, expected):\n",
        "    act = discretizeEqualFrequency(arr, k)\n",
        "    print (\"Equal Count Discretization: \" + (\"OK\" if all(act == expected) else \"FAIL\"))\n",
        "    print(act)\n",
        "    print(expected)\n",
        "\n",
        "# reproduce results from the lecture\n",
        "dfIrisTest = pd.read_csv(\"iris.csv\")\n",
        "test_discretization(dfIrisTest.values[:,0], [5.2, 6.1, 7], [\"very short\", \"short\", \"long\", \"very long\"], [\"very short\", \"very short\", \"very short\", \"very short\", \"very short\", \"short\", \"very short\", \"very short\", \"very short\", \"very short\", \"short\", \"very short\", \"very short\", \"very short\", \"short\", \"short\", \"short\", \"very short\", \"short\", \"very short\", \"short\", \"very short\", \"very short\", \"very short\", \"very short\", \"very short\", \"very short\", \"very short\", \"very short\", \"very short\", \"very short\", \"short\", \"very short\", \"short\", \"very short\", \"very short\", \"short\", \"very short\", \"very short\", \"very short\", \"very short\", \"very short\", \"very short\", \"very short\", \"very short\", \"very short\", \"very short\", \"very short\", \"short\", \"very short\", \"long\", \"long\", \"long\", \"short\", \"long\", \"short\", \"long\", \"very short\", \"long\", \"very short\", \"very short\", \"short\", \"short\", \"short\", \"short\", \"long\", \"short\", \"short\", \"long\", \"short\", \"short\", \"short\", \"long\", \"short\", \"long\", \"long\", \"long\", \"long\", \"short\", \"short\", \"short\", \"short\", \"short\", \"short\", \"short\", \"short\", \"long\", \"long\", \"short\", \"short\", \"short\", \"short\", \"short\", \"very short\", \"short\", \"short\", \"short\", \"long\", \"very short\", \"short\", \"long\", \"short\", \"very long\", \"long\", \"long\", \"very long\", \"very short\", \"very long\", \"long\", \"very long\", \"long\", \"long\", \"long\", \"short\", \"short\", \"long\", \"long\", \"very long\", \"very long\", \"short\", \"long\", \"short\", \"very long\", \"long\", \"long\", \"very long\", \"long\", \"short\", \"long\", \"very long\", \"very long\", \"very long\", \"long\", \"long\", \"short\", \"very long\", \"long\", \"long\", \"short\", \"long\", \"long\", \"long\", \"short\", \"long\", \"long\", \"long\", \"long\", \"long\", \"long\", \"short\"])\n",
        "test_discretization(dfIrisTest.values[:,1], [2.8, 3.6], [\"short\", \"medium\", \"long\"], [\"medium\", \"medium\", \"medium\", \"medium\", \"medium\", \"long\", \"medium\", \"medium\", \"medium\", \"medium\", \"long\", \"medium\", \"medium\", \"medium\", \"long\", \"long\", \"long\", \"medium\", \"long\", \"long\", \"medium\", \"long\", \"medium\", \"medium\", \"medium\", \"medium\", \"medium\", \"medium\", \"medium\", \"medium\", \"medium\", \"medium\", \"long\", \"long\", \"medium\", \"medium\", \"medium\", \"medium\", \"medium\", \"medium\", \"medium\", \"short\", \"medium\", \"medium\", \"long\", \"medium\", \"long\", \"medium\", \"long\", \"medium\", \"medium\", \"medium\", \"medium\", \"short\", \"short\", \"short\", \"medium\", \"short\", \"medium\", \"short\", \"short\", \"medium\", \"short\", \"medium\", \"medium\", \"medium\", \"medium\", \"short\", \"short\", \"short\", \"medium\", \"short\", \"short\", \"short\", \"medium\", \"medium\", \"short\", \"medium\", \"medium\", \"short\", \"short\", \"short\", \"short\", \"short\", \"medium\", \"medium\", \"medium\", \"short\", \"medium\", \"short\", \"short\", \"medium\", \"short\", \"short\", \"short\", \"medium\", \"medium\", \"medium\", \"short\", \"short\", \"medium\", \"short\", \"medium\", \"medium\", \"medium\", \"medium\", \"short\", \"medium\", \"short\", \"medium\", \"medium\", \"short\", \"medium\", \"short\", \"short\", \"medium\", \"medium\", \"long\", \"short\", \"short\", \"medium\", \"short\", \"short\", \"short\", \"medium\", \"medium\", \"short\", \"medium\", \"short\", \"medium\", \"short\", \"long\", \"short\", \"short\", \"short\", \"medium\", \"medium\", \"medium\", \"medium\", \"medium\", \"medium\", \"medium\", \"short\", \"medium\", \"medium\", \"medium\", \"short\", \"medium\", \"medium\", \"medium\"])\n",
        "test_equal_length_discretization(dfIrisTest.values[:,0], 4, np.array([\"c0\", \"c0\", \"c0\", \"c0\", \"c0\", \"c1\", \"c0\", \"c0\", \"c0\", \"c0\", \"c1\", \"c0\", \"c0\", \"c0\", \"c1\", \"c1\", \"c1\", \"c0\", \"c1\", \"c0\", \"c1\", \"c0\", \"c0\", \"c0\", \"c0\", \"c0\", \"c0\", \"c0\", \"c0\", \"c0\", \"c0\", \"c1\", \"c0\", \"c1\", \"c0\", \"c0\", \"c1\", \"c0\", \"c0\", \"c0\", \"c0\", \"c0\", \"c0\", \"c0\", \"c0\", \"c0\", \"c0\", \"c0\", \"c1\", \"c0\", \"c2\", \"c2\", \"c2\", \"c1\", \"c2\", \"c1\", \"c2\", \"c0\", \"c2\", \"c0\", \"c0\", \"c1\", \"c1\", \"c1\", \"c1\", \"c2\", \"c1\", \"c1\", \"c2\", \"c1\", \"c1\", \"c1\", \"c2\", \"c1\", \"c2\", \"c2\", \"c2\", \"c2\", \"c1\", \"c1\", \"c1\", \"c1\", \"c1\", \"c1\", \"c1\", \"c1\", \"c2\", \"c2\", \"c1\", \"c1\", \"c1\", \"c1\", \"c1\", \"c0\", \"c1\", \"c1\", \"c1\", \"c2\", \"c0\", \"c1\", \"c2\", \"c1\", \"c3\", \"c2\", \"c2\", \"c3\", \"c0\", \"c3\", \"c2\", \"c3\", \"c2\", \"c2\", \"c2\", \"c1\", \"c1\", \"c2\", \"c2\", \"c3\", \"c3\", \"c1\", \"c2\", \"c1\", \"c3\", \"c2\", \"c2\", \"c3\", \"c2\", \"c1\", \"c2\", \"c3\", \"c3\", \"c3\", \"c2\", \"c2\", \"c1\", \"c3\", \"c2\", \"c2\", \"c1\", \"c2\", \"c2\", \"c2\", \"c1\", \"c2\", \"c2\", \"c2\", \"c2\", \"c2\", \"c2\", \"c1\"]))\n",
        "test_equal_count_discretization(dfIrisTest.values[:,0], 4, np.array([\"c0\", \"c0\", \"c0\", \"c0\", \"c0\", \"c1\", \"c0\", \"c0\", \"c0\", \"c0\", \"c1\", \"c0\", \"c0\", \"c0\", \"c1\", \"c1\", \"c1\", \"c0\", \"c1\", \"c0\", \"c1\", \"c0\", \"c0\", \"c0\", \"c0\", \"c0\", \"c0\", \"c1\", \"c1\", \"c0\", \"c0\", \"c1\", \"c1\", \"c1\", \"c0\", \"c0\", \"c1\", \"c0\", \"c0\", \"c0\", \"c0\", \"c0\", \"c0\", \"c0\", \"c0\", \"c0\", \"c0\", \"c0\", \"c1\", \"c0\", \"c3\", \"c2\", \"c3\", \"c1\", \"c3\", \"c1\", \"c2\", \"c0\", \"c3\", \"c1\", \"c0\", \"c2\", \"c2\", \"c2\", \"c1\", \"c3\", \"c1\", \"c1\", \"c2\", \"c1\", \"c2\", \"c2\", \"c2\", \"c2\", \"c2\", \"c3\", \"c3\", \"c3\", \"c2\", \"c1\", \"c1\", \"c1\", \"c1\", \"c2\", \"c1\", \"c2\", \"c3\", \"c2\", \"c1\", \"c1\", \"c1\", \"c2\", \"c1\", \"c0\", \"c1\", \"c1\", \"c1\", \"c2\", \"c0\", \"c1\", \"c2\", \"c1\", \"c3\", \"c2\", \"c3\", \"c3\", \"c0\", \"c3\", \"c3\", \"c3\", \"c3\", \"c2\", \"c3\", \"c1\", \"c1\", \"c2\", \"c3\", \"c3\", \"c3\", \"c2\", \"c3\", \"c1\", \"c3\", \"c2\", \"c3\", \"c3\", \"c2\", \"c2\", \"c2\", \"c3\", \"c3\", \"c3\", \"c2\", \"c2\", \"c2\", \"c3\", \"c2\", \"c2\", \"c2\", \"c3\", \"c3\", \"c3\", \"c1\", \"c3\", \"c3\", \"c3\", \"c2\", \"c3\", \"c2\", \"c2\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awEQOODtkdim"
      },
      "source": [
        "### 3\n",
        "In this exercise we want to check the independence of categorical attributes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwzDPC43ZI9J"
      },
      "source": [
        "#### a)\n",
        "Write a function getContingencyTable(M) that receives a 2D numpy array with\n",
        "two columns and computes a table containing the absolute observed frequenties of\n",
        "the pairs of occuring values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "4Wy0r72riIKl"
      },
      "outputs": [],
      "source": [
        "def getContingencyTable(M):\n",
        "  M_transposed = M.T\n",
        "  M_zipped = list(zip(M_transposed[0], M_transposed[1]))\n",
        "  y_categories, x_categories = (set(M_transposed[0]), set(M_transposed[1]))\n",
        "  products = list(itertools.product(y_categories, x_categories))\n",
        "  categories = dict(zip(products, np.array([0] * len(products))))\n",
        "  y_index = {item:index for index, item in enumerate(y_categories)} \n",
        "  x_index = {item:index for index, item in enumerate(x_categories)}\n",
        "  result = np.zeros((len(y_categories), len(x_categories)), dtype='int')\n",
        "  for item in M_zipped:\n",
        "    categories[item] = categories[item] + 1\n",
        "  for categorie in categories.items():\n",
        "    result[y_index[categorie[0][0]]][x_index[categorie[0][1]]] = categorie[1]\n",
        "  return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YieWSEP4ZI9J"
      },
      "source": [
        "#### b)\n",
        "Write a function computeExpectedOccurrences(ct) that receives a contingency\n",
        "table and computes a table containing, for each pair of values, the number of\n",
        "occurences one would expect given independency of the attributes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "bCHtzHf7ZI9J"
      },
      "outputs": [],
      "source": [
        "def computeExpectedOccurrences(ct):\n",
        "    total = sum(np.sum(ct, axis=0))\n",
        "    ct_list = ct.tolist()\n",
        "    ct_list_transposed = np.transpose(ct_list).tolist()\n",
        "\n",
        "    result = ct_list.copy()\n",
        "\n",
        "    for i in range(len(ct_list)):\n",
        "        row = np.sum(ct_list[i], dtype=int)\n",
        "        for j in range(len(ct_list_transposed)):\n",
        "            column = np.sum(ct_list_transposed[j], dtype=int)\n",
        "\n",
        "            result[i][j] = ( row * column ) / total\n",
        "\n",
        "    return np.array(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1NKxoVWbEMm"
      },
      "source": [
        "#### c)\n",
        "Write a function computeChiSquare(M) that receives a 2D numpy array with two\n",
        "discrete columns and computes the χ2score of the two attributes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "uZjHwcsJbEMn"
      },
      "outputs": [],
      "source": [
        "def computeChiSquare(M):\n",
        "    O = getContingencyTable(M)\n",
        "    E = computeExpectedOccurrences(O)\n",
        "    X2 = 0\n",
        "    \n",
        "    for i in range(len(O)):\n",
        "        for j in range(len(O[0])):\n",
        "            o = O[i][j]\n",
        "            e = E[i][j]\n",
        "            X2 += ( (o - e ) ** 2 ) / e\n",
        "\n",
        "    return X2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LWZsTwUZQIa"
      },
      "source": [
        "#### Tests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "hdbUfjW6kdim"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------\n",
            "Check for Contingency Table\n",
            "-----------------\n",
            "Dimensionality: OK\n",
            "Sum 1: OK\n",
            "Sum 2: OK\n",
            "-----------------\n",
            "Check for Expected Count Table\n",
            "-----------------\n",
            "Dimensionality: OK\n",
            "Sum 1: OK\n",
            "Sum 2: OK\n",
            "-----------------\n",
            "Chi²-Test\n",
            "-----------------\n",
            "Chi²: OK\n"
          ]
        }
      ],
      "source": [
        "def test_contingency_table(col1, col2):\n",
        "    print(\"-----------------\\nCheck for Contingency Table\\n-----------------\")\n",
        "    M = np.array([col1, col2]).T\n",
        "    ct = getContingencyTable(M)\n",
        "    s2 = np.sum(ct, axis=0)\n",
        "    s1 = np.sum(ct, axis=1)\n",
        "    print(\"Dimensionality: \" + (\"OK\" if len(s1) == len(np.unique(col1)) and len(s2) == len(np.unique(col2)) else \"FAIL (expected dimension \" + str(len(np.unique(col1))) + \" x \" + str(len(np.unique(col2))) + \" but observed \" + str(len(s1)) + \" x \" + str(len(s2)) + \")\"))\n",
        "    print(\"Sum 1: \" + (\"OK\" if sum(s1) == len(col1) else \"FAIL\"))\n",
        "    print(\"Sum 2: \" + (\"OK\" if sum(s2) == len(col2) else \"FAIL\"))\n",
        "    \n",
        "def test_expected_table(ct):\n",
        "    print(\"-----------------\\nCheck for Expected Count Table\\n-----------------\")\n",
        "    cs1 = np.sum(ct, axis=1)\n",
        "    cs2 = np.sum(ct, axis=0)\n",
        "    et = computeExpectedOccurrences(ct)\n",
        "    s2 = np.sum(et, axis=0)\n",
        "    s1 = np.sum(et, axis=1)\n",
        "    print(\"Dimensionality: \" + (\"OK\" if et.shape == ct.shape else \"FAIL (expected dimension \" + str(ct.shape[0]) + \" x \" + str(ct.shape[1]) + \" but observed \" + str(et.shape[0]) + \" x \" + str(et.shape[1]) + \")\"))\n",
        "    print(\"Sum 1: \" + (\"OK\" if len(cs1) == len(s1) and all(np.isclose(cs1, s1)) else \"FAIL\"))\n",
        "    print(\"Sum 2: \" + (\"OK\" if len(cs2) == len(s2) and all(np.isclose(cs2, s2)) else \"FAIL\"))\n",
        "    \n",
        "def test_chi2(M, expected):\n",
        "    print(\"-----------------\\nChi²-Test\\n-----------------\")\n",
        "    chi2 = computeChiSquare(M)\n",
        "    print (\"Chi²: \" + (\"OK\" if np.round(chi2, 2) == expected else \"FAIL\"))\n",
        "\n",
        "    \n",
        "# reproduce results from the lecture\n",
        "dfIrisDisc = pd.read_csv(\"iris_discretized_projected.csv\")\n",
        "test_contingency_table(dfIrisDisc.values[:,0], dfIrisDisc.values[:,1])\n",
        "test_expected_table(getContingencyTable(np.array([dfIrisDisc.values[:,0], dfIrisDisc.values[:,1]]).T))\n",
        "test_chi2(np.array([dfIrisDisc.values[:,0], dfIrisDisc.values[:,1]]).T, 21.8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "om6TikjJbEMo"
      },
      "source": [
        "#### d)\n",
        "Write a function checkIndependence(df, c1, c2, alpha) that receives a Pandas\n",
        "DataFrame and the names of two columns and that returns true iff the indepen-\n",
        "dence hypothesis is sustained in a χ2test (considering the appropriate degree of\n",
        "freedom) for a given confidence threshold α for the p-value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "gRLgrvFHbEMo"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "module 'scipy' has no attribute '_lib'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21492/3280419165.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# from scipy import stats\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'iris.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcheckIndepence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\Python310\\lib\\site-packages\\scipy\\stats\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    451\u001b[0m \"\"\"\n\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 453\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_stats_py\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    454\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_variation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mvariation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mdistributions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\Python310\\lib\\site-packages\\scipy\\stats\\_stats_py.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspecial\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mspecial\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistributions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_mstats_basic\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmstats_basic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m from ._stats_mstats_common import (_find_repeats, linregress, theilslopes,\n",
            "\u001b[1;32mC:\\Python310\\lib\\site-packages\\scipy\\stats\\distributions.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#       instead of `git blame -Lxxx,+x`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_distn_infrastructure\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mrv_discrete\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrv_continuous\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrv_frozen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_continuous_distns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\Python310\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;31m# for root finding for continuous distribution ppf, and max likelihood\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m# estimation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0moptimize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;31m# for functions of continuous distributions (e.g. moments, entropy, cdf)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\Python310\\lib\\site-packages\\scipy\\optimize\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    397\u001b[0m \"\"\"\n\u001b[0;32m    398\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 399\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_optimize\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    400\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_minimize\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_root\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\Python310\\lib\\site-packages\\scipy\\optimize\\_optimize.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m                    asarray, sqrt, Inf, asfarray)\n\u001b[0;32m     32\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLinearOperator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m from ._linesearch import (line_search_wolfe1, line_search_wolfe2,\n\u001b[0;32m     35\u001b[0m                           \u001b[0mline_search_wolfe2\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mline_search\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\Python310\\lib\\site-packages\\scipy\\sparse\\linalg\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    118\u001b[0m \"\"\"\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_isolve\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_dsolve\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_interface\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\Python310\\lib\\site-packages\\scipy\\sparse\\linalg\\_isolve\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#from info import __doc__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0miterative\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mminres\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mminres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mlgmres\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlgmres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\Python310\\lib\\site-packages\\scipy\\sparse\\linalg\\_isolve\\iterative.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    148\u001b[0m                )\n\u001b[0;32m    149\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0mnon_reentrant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0mbicg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mM\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0matol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mM\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpostprocess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_system\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\Python310\\lib\\site-packages\\scipy\\_lib\\_threadsafety.py\u001b[0m in \u001b[0;36mdecorator\u001b[1;34m(func)\u001b[0m\n\u001b[0;32m     55\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"%s is not re-entrant\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[0mlock\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mReentrancyLock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecorate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\Python310\\lib\\site-packages\\scipy\\_lib\\_threadsafety.py\u001b[0m in \u001b[0;36mdecorate\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m     43\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecorate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaller\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mAttributeError\u001b[0m: module 'scipy' has no attribute '_lib'"
          ]
        }
      ],
      "source": [
        "import scipy.stats as stats\n",
        "# from scipy import stats\n",
        "data = pd.read_csv('iris.csv')\n",
        "\n",
        "def checkIndepence(df, c1,c2, alpha):\n",
        "    M = df[[c1,c2]].values\n",
        "    X2 = computeChiSquare(M)\n",
        "    q = (len(M) - 1) * (len(M[0]) - 1)\n",
        "\n",
        "    ppf = stats.chi2.ppf(1 - alpha, q)\n",
        "    print(ppf)\n",
        "    print(q, X2)\n",
        "\n",
        "    return True if X2 < ppf else False\n",
        "\n",
        "\n",
        "checkIndepence(data, 'sepal_length', 'sepal_width', 0.05)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85l4yc1ZbEMo"
      },
      "source": [
        "#### e)\n",
        "Then check independence hypothesis for all pairs of categorical variables of the\n",
        "credit dataset. Plot the χ2curve for every pair of categorical variables with the\n",
        "respective (given) critical point (we assume α = 0.01).\n",
        "Are there pairs of independent variables?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EmhXvdA8bEMo"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "bi2022_1_sheet3_template.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
