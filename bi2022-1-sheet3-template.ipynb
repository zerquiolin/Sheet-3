{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2\n",
    "Use the credits.csv for all the tasks in this exercise (iris datasets\n",
    "only for some unit tests). You might stumble over some difficulties and may want to check\n",
    "the replace and fillna function of Pandas data frames to get rid of missing values. Do not\n",
    "use the get_dummies, digitize, cut, crosstab (or any similar) function in this exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a)\n",
    "Write a function binarizeCategoricalAttributeVector(column) that takes a\n",
    "categorical attribute vector (do not assume a categorical Pandas type) and re-\n",
    "turns an n ×m dimensional numpy array, where m is the number of categorical\n",
    "values occurring in the column and n is the length of the original column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarizeCategoricalAttributeVector(column):\n",
    "    n = len(column)\n",
    "    m = len(set(column))\n",
    "    count = 0\n",
    "    arr = np.zeros((n,m), dtype=int)\n",
    "    for n in range(n):\n",
    "        if (m >= m):\n",
    "            break\n",
    "        arr[n][count] = 1\n",
    "        count += 1\n",
    "    print(arr)\n",
    "    return arr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b)\n",
    "Then write a function getCategoricalAttributes(df) that returns a list of col-\n",
    "umn names of a Pandas DataFrame that contain non-numeric values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c)\n",
    "Finally, write a function readFrameAsMatrix(df) to convert a given DataFrame\n",
    "into a purely numeric nd array such that each categorical attribute with m values\n",
    "is converted into m binary attributes (columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "-----------------\n",
      "Binarization check\n",
      "-----------------\n",
      "Dimension check: OK\n",
      "Occurring values: FAIL (there should only be 0s and 1s in the output.)\n",
      "Coherence: FAIL (all rows must sum up to 1)\n",
      "-----------------\n",
      "Check of category detection\n",
      "-----------------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'getCategoricalAttributes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_30184/1638775726.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[0mdfCreditTest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"credits.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[0mcheck_column_conversion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdfCreditTest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0mcheck_category_detection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdfCreditTest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'workclass'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'education'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'marital-status'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'occupation'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'relationship'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'race'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'sex'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'native-country'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'class'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[0mcheck_frame_conversion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdfCreditTest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m110\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_30184/1638775726.py\u001b[0m in \u001b[0;36mcheck_category_detection\u001b[1;34m(df, expectedcols)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcheck_category_detection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpectedcols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"-----------------\\nCheck of category detection\\n-----------------\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mact\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetCategoricalAttributes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mmissing\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mexpectedcols\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mact\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0munexpected\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mact\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mexpectedcols\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'getCategoricalAttributes' is not defined"
     ]
    }
   ],
   "source": [
    "def check_column_conversion(column):\n",
    "    M = binarizeCategoricalAttributeVector(column)\n",
    "    vals = list(np.unique(M))\n",
    "    sorted(vals)\n",
    "    print(\"-----------------\\nBinarization check\\n-----------------\")\n",
    "    print(\"Dimension check: \" + (\"OK\" if M.shape == (len(column), len(np.unique(column))) else \"FAIL\"))\n",
    "    print(\"Occurring values: \" + (\"OK\" if vals == [0, 1] else \"FAIL (there should only be 0s and 1s in the output.)\"))\n",
    "    print(\"Coherence: \" + (\"OK\" if all(np.sum(M, axis=1) == np.ones(len(column))) else \"FAIL (all rows must sum up to 1)\"))\n",
    "\n",
    "def check_category_detection(df, expectedcols):\n",
    "    print(\"-----------------\\nCheck of category detection\\n-----------------\")\n",
    "    act = getCategoricalAttributes(df)\n",
    "    missing = [c for c in expectedcols if not c in act]\n",
    "    unexpected = [c for c in act if not c in expectedcols]\n",
    "    print(\"Categorical attribute detection: \" + (\"OK\" if len(missing) + len(unexpected) == 0 else \"FAIL (undetected columns: \" + str(missing) + \", wrongly detected columns: \" + str(unexpected) + \")\"))\n",
    "    \n",
    "def check_frame_conversion(df, num_expected_columns):\n",
    "    print(\"-----------------\\nConversion check for data frames\\n-----------------\")\n",
    "    A = readFrameAsMatrix(df)\n",
    "    print(\"Outer Type check: \" + (\"OK\" if type(A) == np.ndarray else \"FAIL (not a numpy array but \" + str(type(A)) + \")\"))\n",
    "    print(\"Inner Type check: \" + (\"OK\" if A.dtype in [float, np.float32, np.float64] else \"FAIL (dtype of matrix should be something numeric like float and not \" + str(A.dtype) + \")\"))\n",
    "    print(\"Dimensionality check: \" + (\"OK\" if len(A) == len(df) and A.shape[1] == num_expected_columns else \"FAIL (expected shape \" + str(len(df)) + \" x \" + str(num_expected_columns) + \", but observed shape \" + str(len(A)) + \" x \" + str(A.shape[1]) + \")\"))\n",
    "\n",
    "\n",
    "## unit test for conversion functions\n",
    "dfCreditTest = pd.read_csv(\"credits.csv\")\n",
    "check_column_conversion(dfCreditTest.values[:,1])\n",
    "check_category_detection(dfCreditTest, ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country', 'class'])\n",
    "check_frame_conversion(dfCreditTest, 110)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_discretization(column, thresholds, names, expected):\n",
    "    conv = discretizeBasedOnThresholds(column, thresholds, names)\n",
    "    print(\"Conversion test: \" + (\"OK\" if len(conv) == len(expected) and all(conv == expected) else \"FAIL (expected \\\"\" + str(expected) +\"\\\" but observed \\\"\" + str(conv) + \"\\\")\"))\n",
    "    \n",
    "def test_equal_length_discretization(arr, k, expected):\n",
    "    act = discretizeEqualLength(arr, k)\n",
    "    print (\"Equal Length Discretization: \" + (\"OK\" if all(act == expected) else \"FAIL\"))\n",
    "    \n",
    "def test_equal_count_discretization(arr, k, expected):\n",
    "    act = discretizeEqualFrequency(arr, k)\n",
    "    print (\"Equal Count Discretization: \" + (\"OK\" if all(act == expected) else \"FAIL\"))\n",
    "\n",
    "# reproduce results from the lecture\n",
    "dfIrisTest = pd.read_csv(\"iris.csv\")\n",
    "test_discretization(dfIris.values[:,0], [5.2, 6.1, 7], [\"very short\", \"short\", \"long\", \"very long\"], [\"very short\", \"very short\", \"very short\", \"very short\", \"very short\", \"short\", \"very short\", \"very short\", \"very short\", \"very short\", \"short\", \"very short\", \"very short\", \"very short\", \"short\", \"short\", \"short\", \"very short\", \"short\", \"very short\", \"short\", \"very short\", \"very short\", \"very short\", \"very short\", \"very short\", \"very short\", \"very short\", \"very short\", \"very short\", \"very short\", \"short\", \"very short\", \"short\", \"very short\", \"very short\", \"short\", \"very short\", \"very short\", \"very short\", \"very short\", \"very short\", \"very short\", \"very short\", \"very short\", \"very short\", \"very short\", \"very short\", \"short\", \"very short\", \"long\", \"long\", \"long\", \"short\", \"long\", \"short\", \"long\", \"very short\", \"long\", \"very short\", \"very short\", \"short\", \"short\", \"short\", \"short\", \"long\", \"short\", \"short\", \"long\", \"short\", \"short\", \"short\", \"long\", \"short\", \"long\", \"long\", \"long\", \"long\", \"short\", \"short\", \"short\", \"short\", \"short\", \"short\", \"short\", \"short\", \"long\", \"long\", \"short\", \"short\", \"short\", \"short\", \"short\", \"very short\", \"short\", \"short\", \"short\", \"long\", \"very short\", \"short\", \"long\", \"short\", \"very long\", \"long\", \"long\", \"very long\", \"very short\", \"very long\", \"long\", \"very long\", \"long\", \"long\", \"long\", \"short\", \"short\", \"long\", \"long\", \"very long\", \"very long\", \"short\", \"long\", \"short\", \"very long\", \"long\", \"long\", \"very long\", \"long\", \"short\", \"long\", \"very long\", \"very long\", \"very long\", \"long\", \"long\", \"short\", \"very long\", \"long\", \"long\", \"short\", \"long\", \"long\", \"long\", \"short\", \"long\", \"long\", \"long\", \"long\", \"long\", \"long\", \"short\"])\n",
    "test_discretization(dfIris.values[:,1], [2.8, 3.6], [\"short\", \"medium\", \"long\"], [\"medium\", \"medium\", \"medium\", \"medium\", \"medium\", \"long\", \"medium\", \"medium\", \"medium\", \"medium\", \"long\", \"medium\", \"medium\", \"medium\", \"long\", \"long\", \"long\", \"medium\", \"long\", \"long\", \"medium\", \"long\", \"medium\", \"medium\", \"medium\", \"medium\", \"medium\", \"medium\", \"medium\", \"medium\", \"medium\", \"medium\", \"long\", \"long\", \"medium\", \"medium\", \"medium\", \"medium\", \"medium\", \"medium\", \"medium\", \"short\", \"medium\", \"medium\", \"long\", \"medium\", \"long\", \"medium\", \"long\", \"medium\", \"medium\", \"medium\", \"medium\", \"short\", \"short\", \"short\", \"medium\", \"short\", \"medium\", \"short\", \"short\", \"medium\", \"short\", \"medium\", \"medium\", \"medium\", \"medium\", \"short\", \"short\", \"short\", \"medium\", \"short\", \"short\", \"short\", \"medium\", \"medium\", \"short\", \"medium\", \"medium\", \"short\", \"short\", \"short\", \"short\", \"short\", \"medium\", \"medium\", \"medium\", \"short\", \"medium\", \"short\", \"short\", \"medium\", \"short\", \"short\", \"short\", \"medium\", \"medium\", \"medium\", \"short\", \"short\", \"medium\", \"short\", \"medium\", \"medium\", \"medium\", \"medium\", \"short\", \"medium\", \"short\", \"medium\", \"medium\", \"short\", \"medium\", \"short\", \"short\", \"medium\", \"medium\", \"long\", \"short\", \"short\", \"medium\", \"short\", \"short\", \"short\", \"medium\", \"medium\", \"short\", \"medium\", \"short\", \"medium\", \"short\", \"long\", \"short\", \"short\", \"short\", \"medium\", \"medium\", \"medium\", \"medium\", \"medium\", \"medium\", \"medium\", \"short\", \"medium\", \"medium\", \"medium\", \"short\", \"medium\", \"medium\", \"medium\"])\n",
    "test_equal_length_discretization(dfIrisTest.values[:,0], 4, np.array([\"c0\", \"c0\", \"c0\", \"c0\", \"c0\", \"c1\", \"c0\", \"c0\", \"c0\", \"c0\", \"c1\", \"c0\", \"c0\", \"c0\", \"c1\", \"c1\", \"c1\", \"c0\", \"c1\", \"c0\", \"c1\", \"c0\", \"c0\", \"c0\", \"c0\", \"c0\", \"c0\", \"c0\", \"c0\", \"c0\", \"c0\", \"c1\", \"c0\", \"c1\", \"c0\", \"c0\", \"c1\", \"c0\", \"c0\", \"c0\", \"c0\", \"c0\", \"c0\", \"c0\", \"c0\", \"c0\", \"c0\", \"c0\", \"c1\", \"c0\", \"c2\", \"c2\", \"c2\", \"c1\", \"c2\", \"c1\", \"c2\", \"c0\", \"c2\", \"c0\", \"c0\", \"c1\", \"c1\", \"c1\", \"c1\", \"c2\", \"c1\", \"c1\", \"c2\", \"c1\", \"c1\", \"c1\", \"c2\", \"c1\", \"c2\", \"c2\", \"c2\", \"c2\", \"c1\", \"c1\", \"c1\", \"c1\", \"c1\", \"c1\", \"c1\", \"c1\", \"c2\", \"c2\", \"c1\", \"c1\", \"c1\", \"c1\", \"c1\", \"c0\", \"c1\", \"c1\", \"c1\", \"c2\", \"c0\", \"c1\", \"c2\", \"c1\", \"c3\", \"c2\", \"c2\", \"c3\", \"c0\", \"c3\", \"c2\", \"c3\", \"c2\", \"c2\", \"c2\", \"c1\", \"c1\", \"c2\", \"c2\", \"c3\", \"c3\", \"c1\", \"c2\", \"c1\", \"c3\", \"c2\", \"c2\", \"c3\", \"c2\", \"c1\", \"c2\", \"c3\", \"c3\", \"c3\", \"c2\", \"c2\", \"c1\", \"c3\", \"c2\", \"c2\", \"c1\", \"c2\", \"c2\", \"c2\", \"c1\", \"c2\", \"c2\", \"c2\", \"c2\", \"c2\", \"c2\", \"c1\"]))\n",
    "test_equal_count_discretization(dfIrisTest.values[:,0], 4, np.array([\"c0\", \"c0\", \"c0\", \"c0\", \"c0\", \"c1\", \"c0\", \"c0\", \"c0\", \"c0\", \"c1\", \"c0\", \"c0\", \"c0\", \"c1\", \"c1\", \"c1\", \"c0\", \"c1\", \"c0\", \"c1\", \"c0\", \"c0\", \"c0\", \"c0\", \"c0\", \"c0\", \"c1\", \"c1\", \"c0\", \"c0\", \"c1\", \"c1\", \"c1\", \"c0\", \"c0\", \"c1\", \"c0\", \"c0\", \"c0\", \"c0\", \"c0\", \"c0\", \"c0\", \"c0\", \"c0\", \"c0\", \"c0\", \"c1\", \"c0\", \"c3\", \"c2\", \"c3\", \"c1\", \"c3\", \"c1\", \"c2\", \"c0\", \"c3\", \"c1\", \"c0\", \"c2\", \"c2\", \"c2\", \"c1\", \"c3\", \"c1\", \"c1\", \"c2\", \"c1\", \"c2\", \"c2\", \"c2\", \"c2\", \"c2\", \"c3\", \"c3\", \"c3\", \"c2\", \"c1\", \"c1\", \"c1\", \"c1\", \"c2\", \"c1\", \"c2\", \"c3\", \"c2\", \"c1\", \"c1\", \"c1\", \"c2\", \"c1\", \"c0\", \"c1\", \"c1\", \"c1\", \"c2\", \"c0\", \"c1\", \"c2\", \"c1\", \"c3\", \"c2\", \"c3\", \"c3\", \"c0\", \"c3\", \"c3\", \"c3\", \"c3\", \"c2\", \"c3\", \"c1\", \"c1\", \"c2\", \"c3\", \"c3\", \"c3\", \"c2\", \"c3\", \"c1\", \"c3\", \"c2\", \"c3\", \"c3\", \"c2\", \"c2\", \"c2\", \"c3\", \"c3\", \"c3\", \"c2\", \"c2\", \"c2\", \"c3\", \"c2\", \"c2\", \"c2\", \"c3\", \"c3\", \"c3\", \"c1\", \"c3\", \"c3\", \"c3\", \"c2\", \"c3\", \"c2\", \"c2\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_contingency_table(col1, col2):\n",
    "    print(\"-----------------\\nCheck for Contingency Table\\n-----------------\")\n",
    "    M = np.array([col1, col2]).T\n",
    "    ct = getContingencyTable(M)\n",
    "    s2 = np.sum(ct, axis=0)\n",
    "    s1 = np.sum(ct, axis=1)\n",
    "    print(\"Dimensionality: \" + (\"OK\" if len(s1) == len(np.unique(col1)) and len(s2) == len(np.unique(col2)) else \"FAIL (expected dimension \" + str(len(np.unique(col1))) + \" x \" + str(len(np.unique(col2))) + \" but observed \" + str(len(s1)) + \" x \" + str(len(s2)) + \")\"))\n",
    "    print(\"Sum 1: \" + (\"OK\" if sum(s1) == len(col1) else \"FAIL\"))\n",
    "    print(\"Sum 2: \" + (\"OK\" if sum(s2) == len(col2) else \"FAIL\"))\n",
    "    \n",
    "def test_expected_table(ct):\n",
    "    print(\"-----------------\\nCheck for Expected Count Table\\n-----------------\")\n",
    "    cs1 = np.sum(ct, axis=1)\n",
    "    cs2 = np.sum(ct, axis=0)\n",
    "    et = computeExpectedOccurrences(ct)\n",
    "    s2 = np.sum(et, axis=0)\n",
    "    s1 = np.sum(et, axis=1)\n",
    "    print(\"Dimensionality: \" + (\"OK\" if et.shape == ct.shape else \"FAIL (expected dimension \" + str(ct.shape[0]) + \" x \" + str(ct.shape[1]) + \" but observed \" + str(et.shape[0]) + \" x \" + str(et.shape[1]) + \")\"))\n",
    "    print(\"Sum 1: \" + (\"OK\" if len(cs1) == len(s1) and all(np.isclose(cs1, s1)) else \"FAIL\"))\n",
    "    print(\"Sum 2: \" + (\"OK\" if len(cs2) == len(s2) and all(np.isclose(cs2, s2)) else \"FAIL\"))\n",
    "    \n",
    "def test_chi2(M, expected):\n",
    "    print(\"-----------------\\nChi²-Test\\n-----------------\")\n",
    "    chi2 = computeChiSquare(M)\n",
    "    print (\"Chi²: \" + (\"OK\" if np.round(chi2, 2) == expected else \"FAIL\"))\n",
    "\n",
    "    \n",
    "# reproduce results from the lecture\n",
    "dfIrisDisc = pd.read_csv(\"iris_discretized_projected.csv\")\n",
    "test_contingency_table(dfIrisDisc.values[:,0], dfIrisDisc.values[:,1])\n",
    "test_expected_table(getContingencyTable(np.array([dfIrisDisc.values[:,0], dfIrisDisc.values[:,1]]).T))\n",
    "test_chi2(np.array([dfIrisDisc.values[:,0], dfIrisDisc.values[:,1]]).T, 21.8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
